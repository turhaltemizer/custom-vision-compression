{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Custom Vision Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Custom Vision \n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "\n",
    "endpoint = \"https://southcentralus.api.cognitive.microsoft.com\"\n",
    "training_key = \"f944c5a7fd3c46ea9f8e8d201385d9cc\"\n",
    "project_name = \"CatsVsDogs\"\n",
    "data_dir = 'data'\n",
    "\n",
<<<<<<< HEAD
    "# Create trainer\n",
    "trainer = CustomVisionTrainingClient(training_key, endpoint=endpoint)\n",
    "\n",
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() \n",
    "    if domain.type == \"ObjectDetection\" and domain.name == \"General (compact)\")\n",
    "\n",
    "# Create a new project\n",
    "project = trainer.create_project(project_name, domain_id=obj_detection_domain.id)"
=======
    "endpoint = 'PREDICTION ENDPOINT' \n",
    "prediction_key = 'PREDICTION KEY' \n",
    "project_id = 'PROJECT ID' \n",
    "iteration_id = 'ITERATION ID'\n",
    "predictor = CustomVisionPredictionClient(prediction_key, endpoint=endpoint)"
>>>>>>> e34db452047b9f624816189fadb0d898d2ced0a5
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 2,
>>>>>>> e34db452047b9f624816189fadb0d898d2ced0a5
   "metadata": {},
   "outputs": [],
   "source": [
    "from coco_pipe import *\n",
    "\n",
    "# Get datastream of cats and dogs COCO images\n",
    "stream = get_coco_stream(\n",
    "    tags=['cat', 'dog'], \n",
    "    ann_file='annotations/instances_val2017.json',\n",
    "    data_dir=data_dir\n",
    ") \n",
    "\n",
    "# Split datastream into training and validation\n",
    "train, val = stream | mp.datasplit(split_value=0.3) | mp.make_train_test_split()\n",
    "\n",
    "# Upload training stream to the Custom Vision service\n",
    "coco_to_custom_vision(\n",
    "    stream=train, \n",
    "    project_id=project.id, \n",
    "    trainer=trainer, \n",
    "    data_dir=data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 3,
>>>>>>> e34db452047b9f624816189fadb0d898d2ced0a5
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Train the model\n",
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(5)\n",
    "\n",
    "# The iteration is now trained. Make it the default project endpoint\n",
    "trainer.update_iteration(project.id, iteration.id, is_default=True)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Models Quantization\n",
    "\n",
    " \n",
    " ### 2.1 CoreML Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing using linear quantization\n",
      "Optimizing Neural Network before Quantization:\n",
      "Finished optimizing network. Quantizing neural network..\n",
      "Quantizing layer layer1/conv\n",
      "Quantizing layer layer2/conv\n",
      "Quantizing layer layer3/conv\n",
      "Quantizing layer layer4/conv\n",
      "Quantizing layer layer5/conv\n",
      "Quantizing layer layer6/conv\n",
      "Quantizing layer layer7/conv\n",
      "Quantizing layer layer8/conv\n",
      "Quantizing layer model_outputs0\n"
     ]
    }
   ],
   "source": [
    "# Compress CoreML model\n",
    "\n",
    "import coremltools\n",
    "\n",
    "# Option 1: convert a full precision (float) MLModel to a 16bit quantized MLModel\n",
    "model_spec = coremltools.utils.load_spec('models/coreml/model.mlmodel')\n",
    "model_fp16_spec = coremltools.utils.convert_neural_network_spec_weights_to_fp16(model_spec)\n",
    "coremltools.utils.save_spec(model_fp16_spec, 'models/coreml/modelFP16.mlmodel')\n",
    "\n",
    "# Option 2: convert a full precision (float) MLModel to a 8bit quantized MLModel\n",
    "model = coremltools.models.MLModel('models/coreml/model.mlmodel')\n",
    "model_fp8 = coremltools.models.neural_network.quantization_utils.quantize_weights(model, nbits=8)\n",
    "model_fp8.save('models/coreml/modelFP8.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup CoreML models\n",
    "\n",
    "from models.coreml.python.predict import *\n",
    "\n",
    "coreml_16 = coremltools.models.MLModel('models/coreml/modelFP16.mlmodel')\n",
    "coreml_8 = coremltools.models.MLModel('models/coreml/modelFP8.mlmodel')\n",
    "coreml_orig = coremltools.models.MLModel('models/coreml/model.mlmodel')\n",
    "\n",
    "with open('models/coreml/labels.txt', 'r') as f:\n",
    "    labels = [l.strip() for l in f.readlines()]\n",
    "\n",
    "od_coreml_16 = CoreMLObjectDetection(coreml_16, labels)\n",
    "od_coreml_8 = CoreMLObjectDetection(coreml_8, labels)\n",
    "od_coreml_orig = CoreMLObjectDetection(coreml_orig, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tensorflow Quantization\n",
    "  \n",
    " ❗️ **Note:** Don't forget to copy ```models.tflite.python.predict_lite``` file while doing experiments on your own model. This file is not uploaded with the exported models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
<<<<<<< HEAD
     "ename": "ConverterError",
     "evalue": "TOCO failed. See console for info.\n/bin/sh: toco_from_protos: command not found\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-be71414d60c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_frozen_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/tflite/model.pb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Placeholder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'model_outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_quantize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtflite_model_8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/tflite/modelFP8.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model_8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m           \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m           \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m           **converter_kwargs)\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       result = _toco_convert_graph_def(\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m   data = toco_convert_protos(model_flags.SerializeToString(),\n\u001b[1;32m    441\u001b[0m                              \u001b[0mtoco_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                              input_data.SerializeToString())\n\u001b[0m\u001b[1;32m    443\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       raise ConverterError(\n\u001b[0;32m--> 205\u001b[0;31m           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n\u001b[0m\u001b[1;32m    206\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConverterError\u001b[0m: TOCO failed. See console for info.\n/bin/sh: toco_from_protos: command not found\n\n\n"
     ]
=======
     "data": {
      "text/plain": [
       "11047480"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
>>>>>>> e34db452047b9f624816189fadb0d898d2ced0a5
    }
   ],
   "source": [
    "# Compress TensorFlow model\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph('models/tensorflow/model.pb', ['Placeholder'], ['model_outputs'])\n",
    "converter.post_training_quantize = True\n",
    "tflite_model_8 = converter.convert()\n",
    "open(\"models/tensorflow/modelFP8.tflite\", \"wb\").write(tflite_model_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-6c3302055d07>:7: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "# Setup TensorFlow Original Model\n",
    "\n",
    "from models.tensorflow.python.predict import TFObjectDetection as OrigTFObjectDetection\n",
    "from models.tensorflow.python.predict_lite import TFObjectDetection as LiteTFObjectDetection\n",
    "\n",
    "graph_orig = tf.GraphDef()\n",
    "with tf.gfile.FastGFile('models/tensorflow/model.pb', 'rb') as f:\n",
    "    graph_orig.ParseFromString(f.read())\n",
    "        \n",
    "# Load labels\n",
    "with open('models/tensorflow/labels.txt', 'r') as f:\n",
    "    labels = [l.strip() for l in f.readlines()]\n",
    "\n",
    "od_tflite_orig = OrigTFObjectDetection(graph_orig, labels)\n",
    "\n",
    "od_tflite_8 = LiteTFObjectDetection('models/tensorflow/modelFP8.tflite', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "\n",
    "prediction_key = ''\n",
    "predictor = CustomVisionPredictionClient(prediction_key, endpoint=endpoint)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 9,
>>>>>>> e34db452047b9f624816189fadb0d898d2ced0a5
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipe import Pipe\n",
    "\n",
<<<<<<< HEAD
    "@Pipe\n",
    "def apply_quantized_model(stream, data_dir, model, dest_field):\n",
    "    return (\n",
    "        stream \n",
    "        | mp.apply('filename', dest_field + '_raw', lambda x: model.predict_image(Image.open(join(data_dir, x))))\n",
    "        | mp.apply([dest_field + '_raw', 'width', 'height'], dest_field, lambda x: x[0]\n",
    "            | mp.select(lambda p: format_dict(p, x[1], x[2]))\n",
    "            | mp.as_list\n",
    "        )\n",
    "        | mp.delfield([dest_field + '_raw'])\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "val2 = (\n",
    "    val\n",
=======
    "stream = (\n",
    "    list(vott_export['frames'].keys()) \n",
    "    | mp.as_field('filename')\n",
    "    | mp.apply('filename', 'meta', lambda x: vott_export['frames'][x])\n",
    "    | mp.filter('meta', lambda x: len(x) > 0)\n",
    "    | mp.apply('meta', 'width', lambda x: x[0]['width'])\n",
    "    | mp.apply('meta', 'height', lambda x: x[0]['height'])\n",
    "    | mp.apply('meta', 'ground_truth', lambda x: x \n",
    "        | mp.select(lambda m: ignore_result(m['box'].update({'tag' : m['tags'][0]}), m['box'])) \n",
    "        | mp.select(lambda m: box_to_whformat(m))\n",
    "        | mp.as_list\n",
    "     )\n",
>>>>>>> e34db452047b9f624816189fadb0d898d2ced0a5
    "    # Predict using online CustomVision\n",
    "    | mp.apply('filename', 'raw_cv', \n",
    "        lambda x: predictor.predict_image(project.id, open(join(data_dir, x), mode=\"rb\"), iteration.id).predictions)\n",
    "    | mp.apply(['raw_cv', 'width', 'height'], 'cv_predictions', lambda x: x[0]\n",
    "        | mp.select(lambda p: cv_prediction_as_dict(p, x[1], x[2]))\n",
    "        | mp.as_list\n",
    "      )    \n",
    "    # Predict using CoreML original\n",
    "    | apply_quantized_model(data_dir, od_coreml_orig, 'coreml_orig_predictions') \n",
    "    | mp.as_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '000000017029.jpg',\n",
       " 'width': 640,\n",
       " 'height': 640,\n",
       " 'ground_truth': [{'x1': 152.34454433313397,\n",
       "   'y1': 136.70542155726676,\n",
       "   'tag': 'dog',\n",
       "   'width': 253.72514204545456,\n",
       "   'height': 400.71093983627395}],\n",
       " 'cv_predictions': [{'tag': 'cat',\n",
       "   'prob': 0.0251565184,\n",
       "   'x1': 1.6910696,\n",
       "   'y1': 32.016565824,\n",
       "   'width': 22.243554624,\n",
       "   'height': 69.92457408},\n",
       "  {'tag': 'cat',\n",
       "   'prob': 0.0114600845,\n",
       "   'x1': 166.8371008,\n",
       "   'y1': 43.881788224,\n",
       "   'width': 33.343028992,\n",
       "   'height': 29.4543936},\n",
       "  {'tag': 'cat',\n",
       "   'prob': 0.0176783111,\n",
       "   'x1': 1.3704752895999999,\n",
       "   'y1': 37.157950400000004,\n",
       "   'width': 50.3039552,\n",
       "   'height': 63.8039808},\n",
       "  {'tag': 'cat',\n",
       "   'prob': 0.01035777,\n",
       "   'x1': 147.9061696,\n",
       "   'y1': 25.294544704000003,\n",
       "   'width': 81.60093312000001,\n",
       "   'height': 74.20054464},\n",
       "  {'tag': 'cat',\n",
       "   'prob': 0.0148153463,\n",
       "   'x1': 4.5161819456000005,\n",
       "   'y1': 451.24053951999997,\n",
       "   'width': 199.10659776,\n",
       "   'height': 83.392256},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0775669441,\n",
       "   'x1': 1.6910696,\n",
       "   'y1': 32.016565824,\n",
       "   'width': 22.243554624,\n",
       "   'height': 69.92457408},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.04091575,\n",
       "   'x1': 166.8371008,\n",
       "   'y1': 43.881788224,\n",
       "   'width': 33.343028992,\n",
       "   'height': 29.4543936},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0105429962,\n",
       "   'x1': 5.14743232,\n",
       "   'y1': 500.25226624,\n",
       "   'width': 11.089823232,\n",
       "   'height': 60.9187712},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0432246774,\n",
       "   'x1': 1.3704752895999999,\n",
       "   'y1': 37.157950400000004,\n",
       "   'width': 50.3039552,\n",
       "   'height': 63.8039808},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0163939763,\n",
       "   'x1': 147.9061696,\n",
       "   'y1': 25.294544704000003,\n",
       "   'width': 81.60093312000001,\n",
       "   'height': 74.20054464},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0277944561,\n",
       "   'x1': 57.7716544,\n",
       "   'y1': 120.70779776,\n",
       "   'width': 78.03153024,\n",
       "   'height': 41.501369600000004},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.01024178,\n",
       "   'x1': 75.93101951999999,\n",
       "   'y1': 165.16311616,\n",
       "   'width': 128.68087744000002,\n",
       "   'height': 53.2542208},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0117583871,\n",
       "   'x1': 70.446224,\n",
       "   'y1': 185.41431423999998,\n",
       "   'width': 134.65011199999998,\n",
       "   'height': 53.108367936},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.02721668,\n",
       "   'x1': 130.81271168,\n",
       "   'y1': 230.58532736,\n",
       "   'width': 95.35660800000001,\n",
       "   'height': 56.871452352},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0209365636,\n",
       "   'x1': 246.13277440000002,\n",
       "   'y1': 422.906816,\n",
       "   'width': 115.112576,\n",
       "   'height': 91.26449600000001},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0374790244,\n",
       "   'x1': 19.4552896,\n",
       "   'y1': 463.21826944000003,\n",
       "   'width': 87.97060031999999,\n",
       "   'height': 57.8039168},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.07899927,\n",
       "   'x1': 52.694412799999995,\n",
       "   'y1': 464.61824,\n",
       "   'width': 92.38830592,\n",
       "   'height': 54.2782592},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.01937367,\n",
       "   'x1': 110.01285568,\n",
       "   'y1': 0.0,\n",
       "   'width': 128.375168,\n",
       "   'height': 147.07828544},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.03371256,\n",
       "   'x1': 53.75101088,\n",
       "   'y1': 1.8343544,\n",
       "   'width': 165.822272,\n",
       "   'height': 184.26038720000003},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0307676625,\n",
       "   'x1': 196.762816,\n",
       "   'y1': 0.0,\n",
       "   'width': 121.12094848,\n",
       "   'height': 218.9504},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0122669069,\n",
       "   'x1': 262.658048,\n",
       "   'y1': 218.01006336,\n",
       "   'width': 131.27151488,\n",
       "   'height': 317.058368},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0117666824,\n",
       "   'x1': 82.82262784,\n",
       "   'y1': 21.958279616,\n",
       "   'width': 362.973184,\n",
       "   'height': 150.9354976},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.0154441791,\n",
       "   'x1': 375.65410624000003,\n",
       "   'y1': 36.315808000000004,\n",
       "   'width': 230.69187136,\n",
       "   'height': 103.094848},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.01438937,\n",
       "   'x1': 4.5161819456000005,\n",
       "   'y1': 451.24053951999997,\n",
       "   'width': 199.10659776,\n",
       "   'height': 83.392256},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.155893311,\n",
       "   'x1': 132.07180032,\n",
       "   'y1': 27.813034048,\n",
       "   'width': 323.02524544,\n",
       "   'height': 404.17404159999995},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.919840336,\n",
       "   'x1': 185.7883072,\n",
       "   'y1': 125.455168,\n",
       "   'width': 221.67301184,\n",
       "   'height': 420.280768},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.028401861,\n",
       "   'x1': 0.0,\n",
       "   'y1': 160.71958528,\n",
       "   'width': 366.99752832,\n",
       "   'height': 440.24162304000004}],\n",
       " 'coreml_orig_predictions': [{'tag': 'dog',\n",
       "   'prob': 0.65784283,\n",
       "   'x1': 142.2705216,\n",
       "   'y1': 44.15024,\n",
       "   'width': 274.3245376,\n",
       "   'height': 465.3858624},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.13982406,\n",
       "   'x1': 195.1163968,\n",
       "   'y1': 180.59279360000002,\n",
       "   'width': 164.920128,\n",
       "   'height': 361.75365120000004},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.10638647,\n",
       "   'x1': 7.6731584,\n",
       "   'y1': 28.119584,\n",
       "   'width': 22.3480512,\n",
       "   'height': 76.889728}],\n",
       " 'coreml_16_predictions': [{'tag': 'dog',\n",
       "   'prob': 0.65784283,\n",
       "   'x1': 142.2705216,\n",
       "   'y1': 44.15024,\n",
       "   'width': 274.3245376,\n",
       "   'height': 465.3858624},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.13982406,\n",
       "   'x1': 195.1163968,\n",
       "   'y1': 180.59279360000002,\n",
       "   'width': 164.920128,\n",
       "   'height': 361.75365120000004},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.10638647,\n",
       "   'x1': 7.6731584,\n",
       "   'y1': 28.119584,\n",
       "   'width': 22.3480512,\n",
       "   'height': 76.889728}],\n",
       " 'coreml_8_predictions': [{'tag': 'dog',\n",
       "   'prob': 0.64735119,\n",
       "   'x1': 171.0817856,\n",
       "   'y1': 96.1511552,\n",
       "   'width': 269.9396928,\n",
       "   'height': 424.1979648}],\n",
       " 'tf_orig_predictions': [{'tag': 'dog',\n",
       "   'prob': 0.65823114,\n",
       "   'x1': 142.3706176,\n",
       "   'y1': 44.1922752,\n",
       "   'width': 274.190496,\n",
       "   'height': 465.3406784},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.13976985,\n",
       "   'x1': 195.1139392,\n",
       "   'y1': 180.46159360000001,\n",
       "   'width': 164.9667968,\n",
       "   'height': 361.9748288},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.10660028,\n",
       "   'x1': 7.6555903999999995,\n",
       "   'y1': 28.0493376,\n",
       "   'width': 22.354495999999997,\n",
       "   'height': 77.0243072}],\n",
       " 'tf_8_predictions': [{'tag': 'dog',\n",
       "   'prob': 0.65928632,\n",
       "   'x1': 171.087424,\n",
       "   'y1': 112.7445952,\n",
       "   'width': 275.6819712,\n",
       "   'height': 398.0563968},\n",
       "  {'tag': 'dog',\n",
       "   'prob': 0.11623665,\n",
       "   'x1': 39.0534784,\n",
       "   'y1': -5.4910208,\n",
       "   'width': 179.56240000000003,\n",
       "   'height': 167.8430272}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> e34db452047b9f624816189fadb0d898d2ced0a5
   "source": [
    "stream[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(stream, open('results.pickle', 'wb'))\n",
    "# stream = pickle.load(open('results.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== cv_predictions =====\n",
      "\n",
      "Tag             |  Precision   |    Recall   \n",
      "---------------------------------------------\n",
      "cat             |   0.89474    |   0.15741   \n",
      "dog             |     0.5      |   0.23894   \n",
      "\n",
      "===== coreml_orig_predictions =====\n",
      "\n",
      "Tag             |  Precision   |    Recall   \n",
      "---------------------------------------------\n",
      "cat             |     1.0      |   0.083333  \n",
      "dog             |   0.55556    |   0.26549   \n",
      "\n",
      "===== coreml_16_predictions =====\n",
      "\n",
      "Tag             |  Precision   |    Recall   \n",
      "---------------------------------------------\n",
      "cat             |     1.0      |   0.083333  \n",
      "dog             |   0.55556    |   0.26549   \n",
      "\n",
      "===== coreml_8_predictions =====\n",
      "\n",
      "Tag             |  Precision   |    Recall   \n",
      "---------------------------------------------\n",
      "cat             |   0.31579    |   0.11111   \n",
      "dog             |     0.52     |   0.23009   \n",
      "\n",
      "===== tf_orig_predictions =====\n",
      "\n",
      "Tag             |  Precision   |    Recall   \n",
      "---------------------------------------------\n",
      "cat             |     1.0      |   0.083333  \n",
      "dog             |   0.55556    |   0.26549   \n",
      "\n",
      "===== tf_8_predictions =====\n",
      "\n",
      "Tag             |  Precision   |    Recall   \n",
      "---------------------------------------------\n",
      "cat             |     1.0      |   0.083333  \n",
      "dog             |   0.59649    |   0.30088   \n"
     ]
    }
   ],
>>>>>>> e34db452047b9f624816189fadb0d898d2ced0a5
   "source": [
    "# Print reports\n",
    "\n",
    "\n",
    "for pred_field in [key for key in stream[0].keys() if 'predictions' in key]:\n",
    "    print(\"\\n===== %s =====\\n\" % pred_field)\n",
    "    print_report(\n",
    "        stream=val, \n",
    "        input_tags=input_tags, \n",
    "        prob_thresh=0.3, \n",
    "        overlap_thresh=0.3,\n",
    "        pred_field=pred_field, \n",
    "        gt_field='ground_truth'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
