{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup CustomVision credentials\n",
    "\n",
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "\n",
    "endpoint = 'ENDPOINT'\n",
    "prediction_key = 'PREDICTION_KEY'\n",
    "project_id = 'PROJECT_ID'\n",
    "iteration_id = 'ITERATION_ID'\n",
    "predictor = CustomVisionPredictionClient(prediction_key, endpoint=endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load prerequisits \n",
    "\n",
    "import mPyPl as mp\n",
    "import json \n",
    "from os.path import join\n",
    "from metrics import *\n",
    "from PIL import Image\n",
    "\n",
    "data_dir = '../data/Tagged'\n",
    "vott_export = json.load(open('../data/Tagged.json', 'r'))\n",
    "test_images = json.load(open('test_images.json', 'r'))\n",
    "test_images = test_images['test_images']\n",
    "input_tags = vott_export['inputTags'].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some useful functions \n",
    "\n",
    "def ignore_result(func, value):\n",
    "    return func or value\n",
    "\n",
    "def box_to_whformat(box):\n",
    "    box['width'] = abs(box['x2'] - box['x1'])\n",
    "    box['height'] = abs(box['y2'] - box['y1'])\n",
    "    box.pop('x2', None)\n",
    "    box.pop('y2', None)\n",
    "    return box\n",
    "\n",
    "def prediction_as_dict(prediction, width=None, height=None):\n",
    "    return {\n",
    "        'tag' : prediction.tag_name,\n",
    "        'prob' : prediction.probability,\n",
    "        'x1' : prediction.bounding_box.left * width if width else prediction.bounding_box.left,\n",
    "        'y1' : prediction.bounding_box.top * height if height else prediction.bounding_box.top,\n",
    "        'width' : prediction.bounding_box.width * width if width else prediction.bounding_box.width,\n",
    "        'height' : prediction.bounding_box.height * height if height else prediction.bounding_box.height\n",
    "    }\n",
    "\n",
    "def format_dict(prediction, width=None, height=None):\n",
    "    return {\n",
    "        'tag' : prediction['tagName'],\n",
    "        'prob' : prediction['probability'],\n",
    "        'x1' : prediction['boundingBox']['left'] * width if width else prediction['boundingBox']['left'],\n",
    "        'y1' : prediction['boundingBox']['top'] * height if height else prediction['boundingBox']['top'],\n",
    "        'width' : prediction['boundingBox']['width'] * width if width else prediction['boundingBox']['width'],\n",
    "        'height' : prediction['boundingBox']['height'] * height if height else prediction['boundingBox']['height']\n",
    "    }\n",
    "\n",
    "def print_report(stream, input_tags, pred_field='predictions', gt_field='ground_truth'):\n",
    "    top = '{:15.12} | {:^12.10} | {:^12.10}'.format(\"Tag\", \"Precision\", \"Recall\")\n",
    "    print(top)\n",
    "    print('-' * len(top))\n",
    "    for tag in input_tags:\n",
    "        precision, recall = precision_recall(stream, tag, 0.5, 0.3, pred_field=pred_field, gt_field=gt_field)\n",
    "        print('{:15.12} | {:^12.5} | {:^12.5}'.format(tag, float(precision), float(recall)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress CoreML model\n",
    "\n",
    "import coremltools\n",
    "\n",
    "# Option 1: convert a full precision (float) MLModel to a 16bit quantized MLModel\n",
    "model_spec = coremltools.utils.load_spec('coreml/model.mlmodel')\n",
    "model_fp16_spec = coremltools.utils.convert_neural_network_spec_weights_to_fp16(model_spec)\n",
    "coremltools.utils.save_spec(model_fp16_spec, 'coreml/modelFP16.mlmodel')\n",
    "\n",
    "# Option 2: convert a full precision (float) MLModel to a 8bit quantized MLModel\n",
    "model = coremltools.models.MLModel('coreml/model.mlmodel')\n",
    "model_fp8 = coremltools.models.neural_network.quantization_utils.quantize_weights(model, nbits=8)\n",
    "coremltools.utils.save_spec(model_fp8, 'coreml/modelFP8.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup CoreML models\n",
    "\n",
    "from coreml.python.predict import *\n",
    "\n",
    "coreml_16 = coremltools.models.MLModel('coreml/modelFP16.mlmodel')\n",
    "coreml_8 = coremltools.models.MLModel('coreml/modelFP8.mlmodel')\n",
    "coreml_orig = coremltools.models.MLModel('coreml/model.mlmodel')\n",
    "\n",
    "with open('coreml/labels.txt', 'r') as f:\n",
    "    labels = [l.strip() for l in f.readlines()]\n",
    "\n",
    "od_coreml_16 = CoreMLObjectDetection(coreml_16, labels)\n",
    "od_coreml_8 = CoreMLObjectDetection(coreml_8, labels)\n",
    "od_coreml_orig = CoreMLObjectDetection(coreml_orig, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress TensorFlow model\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph('tflite/model.pb', ['Placeholder'], ['model_outputs'])\n",
    "converter.post_training_quantize = True\n",
    "tflite_model_8 = converter.convert()\n",
    "open(\"tflite/modelFP8.tflite\", \"wb\").write(tflite_model_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TensorFlow Original Model\n",
    "\n",
    "from tflite.python.predict import TFObjectDetection as OrigTFObjectDetection\n",
    "from tflite.python.predict_lite import TFObjectDetection as LiteTFObjectDetection\n",
    "\n",
    "graph_orig = tf.GraphDef()\n",
    "with tf.gfile.FastGFile('tflite/model.pb', 'rb') as f:\n",
    "    graph_orig.ParseFromString(f.read())\n",
    "        \n",
    "# Load labels\n",
    "with open('tflite/labels.txt', 'r') as f:\n",
    "    labels = [l.strip() for l in f.readlines()]\n",
    "\n",
    "od_tflite_orig = OrigTFObjectDetection(graph_orig, labels)\n",
    "\n",
    "od_tflite_8 = LiteTFObjectDetection('tflite/modelFP8.tflite', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup datastream\n",
    "\n",
    "stream = (\n",
    "    list(vott_export['frames'].keys()) \n",
    "    #| mp.where(lambda x: x in test_images)\n",
    "    | mp.as_field('filename')\n",
    "    | mp.apply('filename', 'meta', lambda x: vott_export['frames'][x])\n",
    "    | mp.apply('meta', 'width', lambda x: x[0]['width'])\n",
    "    | mp.apply('meta', 'height', lambda x: x[0]['height'])\n",
    "    | mp.apply('meta', 'ground_truth', lambda x: x \n",
    "        | mp.select(lambda m: ignore_result(m['box'].update({'tag' : m['tags'][0]}), m['box'])) \n",
    "        | mp.select(lambda m: box_to_whformat(m))\n",
    "        | mp.as_list\n",
    "     )\n",
    "    # Predict using online CustomVision\n",
    "    | mp.apply('filename', 'raw_cv', \n",
    "        lambda x: predictor.predict_image(project_id, open(join(data_dir, x), mode=\"rb\"), iteration_id).predictions)\n",
    "    | mp.apply(['raw_cv', 'width', 'height'], 'cv_predictions', lambda x: x[0]\n",
    "        | mp.select(lambda p: prediction_as_dict(p, x[1], x[2]))\n",
    "        | mp.as_list\n",
    "      )     \n",
    "    # Predict using CoreML original\n",
    "    | mp.apply('filename', 'coreml_orig_raw', lambda x: od_coreml_orig.predict_image(Image.open(join(data_dir, x))))\n",
    "    | mp.apply(['coreml_orig_raw', 'width', 'height'], 'coreml_orig_predictions', lambda x: x[0]\n",
    "        | mp.select(lambda p: format_dict(p, x[1], x[2]))\n",
    "        | mp.as_list\n",
    "      )  \n",
    "    # Predict using CoreML compressed to 16FP\n",
    "    | mp.apply('filename', 'coreml_16_raw', lambda x: od_coreml_16.predict_image(Image.open(join(data_dir, x))))\n",
    "    | mp.apply(['coreml_16_raw', 'width', 'height'], 'coreml_16_predictions', lambda x: x[0]\n",
    "        | mp.select(lambda p: format_dict(p, x[1], x[2]))\n",
    "        | mp.as_list\n",
    "      )  \n",
    "    # Predict using CoreML compressed to 8FP\n",
    "    | mp.apply('filename', 'coreml_8_raw', lambda x: od_coreml_8.predict_image(Image.open(join(data_dir, x))))\n",
    "    | mp.apply(['coreml_8_raw', 'width', 'height'], 'coreml_8_predictions', lambda x: x[0]\n",
    "        | mp.select(lambda p: format_dict(p, x[1], x[2]))\n",
    "        | mp.as_list\n",
    "      )  \n",
    "    # Predict using TensorFlow original\n",
    "    | mp.apply('filename', 'tf_orig_raw', lambda x: od_tflite_orig.predict_image(Image.open(join(data_dir, x))))\n",
    "    | mp.apply(['tf_orig_raw', 'width', 'height'], 'tf_orig_predictions', lambda x: x[0]\n",
    "        | mp.select(lambda p: format_dict(p, x[1], x[2]))\n",
    "        | mp.as_list\n",
    "      ) \n",
    "    # Predict using TensorFlow compressed to 8FP\n",
    "    | mp.apply('filename', 'tf_8_raw', lambda x: od_tflite_8.predict_image(Image.open(join(data_dir, x))))\n",
    "    | mp.apply(['tf_8_raw', 'width', 'height'], 'tf_8_predictions', lambda x: x[0]\n",
    "        | mp.select(lambda p: format_dict(p, x[1], x[2]))\n",
    "        | mp.as_list\n",
    "      ) \n",
    "    | mp.delfield(['meta', 'raw_cv', 'coreml_orig_raw', 'coreml_16_raw', 'coreml_8_raw', 'tf_orig_raw', 'tf_8_raw'])\n",
    "    | mp.as_list\n",
    ")\n",
    "\n",
    "stream[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(stream, open('results.pickle', 'wb'))\n",
    "# stream = pickle.load(open('results.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print reports\n",
    "\n",
    "for pred_field in [key for key in stream[0].keys() if 'predictions' in key]:\n",
    "    print(\"\\n===== %s =====\\n\" % pred_field)\n",
    "    print_report(stream, input_tags, pred_field=pred_field, gt_field='ground_truth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
