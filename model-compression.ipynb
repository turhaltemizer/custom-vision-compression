{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Custom Vision Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Custom Vision \n",
    "from azure.cognitiveservices.vision.customvision.training import CustomVisionTrainingClient\n",
    "\n",
    "endpoint = \"https://southcentralus.api.cognitive.microsoft.com\"\n",
    "training_key = \"f944c5a7fd3c46ea9f8e8d201385d9cc\"\n",
    "project_name = \"CatsVsDogs\"\n",
    "data_dir = 'data'\n",
    "\n",
    "# Create trainer\n",
    "trainer = CustomVisionTrainingClient(training_key, endpoint=endpoint)\n",
    "\n",
    "# Find the object detection domain\n",
    "obj_detection_domain = next(domain for domain in trainer.get_domains() \n",
    "    if domain.type == \"ObjectDetection\" and domain.name == \"General (compact)\")\n",
    "\n",
    "# Create a new project\n",
    "project = trainer.create_project(project_name, domain_id=obj_detection_domain.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coco_pipe import *\n",
    "\n",
    "# Get datastream of cats and dogs COCO images\n",
    "stream = get_coco_stream(\n",
    "    tags=['cat', 'dog'], \n",
    "    ann_file='annotations/instances_val2017.json',\n",
    "    data_dir=data_dir\n",
    ") \n",
    "\n",
    "# Split datastream into training and validation\n",
    "train, val = stream | mp.datasplit(split_value=0.3) | mp.make_train_test_split()\n",
    "\n",
    "# Upload training stream to the Custom Vision service\n",
    "coco_to_custom_vision(\n",
    "    stream=train, \n",
    "    project_id=project.id, \n",
    "    trainer=trainer, \n",
    "    data_dir=data_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Train the model\n",
    "print (\"Training...\")\n",
    "iteration = trainer.train_project(project.id)\n",
    "while (iteration.status != \"Completed\"):\n",
    "    iteration = trainer.get_iteration(project.id, iteration.id)\n",
    "    print (\"Training status: \" + iteration.status)\n",
    "    time.sleep(5)\n",
    "\n",
    "# The iteration is now trained. Make it the default project endpoint\n",
    "trainer.update_iteration(project.id, iteration.id, is_default=True)\n",
    "print (\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Models Quantization\n",
    "\n",
    " \n",
    " ### 2.1 CoreML Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing using linear quantization\n",
      "Optimizing Neural Network before Quantization:\n",
      "Finished optimizing network. Quantizing neural network..\n",
      "Quantizing layer layer1/conv\n",
      "Quantizing layer layer2/conv\n",
      "Quantizing layer layer3/conv\n",
      "Quantizing layer layer4/conv\n",
      "Quantizing layer layer5/conv\n",
      "Quantizing layer layer6/conv\n",
      "Quantizing layer layer7/conv\n",
      "Quantizing layer layer8/conv\n",
      "Quantizing layer model_outputs0\n"
     ]
    }
   ],
   "source": [
    "# Compress CoreML model\n",
    "\n",
    "import coremltools\n",
    "\n",
    "# Option 1: convert a full precision (float) MLModel to a 16bit quantized MLModel\n",
    "model_spec = coremltools.utils.load_spec('models/coreml/model.mlmodel')\n",
    "model_fp16_spec = coremltools.utils.convert_neural_network_spec_weights_to_fp16(model_spec)\n",
    "coremltools.utils.save_spec(model_fp16_spec, 'models/coreml/modelFP16.mlmodel')\n",
    "\n",
    "# Option 2: convert a full precision (float) MLModel to a 8bit quantized MLModel\n",
    "model = coremltools.models.MLModel('models/coreml/model.mlmodel')\n",
    "model_fp8 = coremltools.models.neural_network.quantization_utils.quantize_weights(model, nbits=8)\n",
    "model_fp8.save('models/coreml/modelFP8.mlmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup CoreML models\n",
    "\n",
    "from models.coreml.python.predict import *\n",
    "\n",
    "coreml_16 = coremltools.models.MLModel('models/coreml/modelFP16.mlmodel')\n",
    "coreml_8 = coremltools.models.MLModel('models/coreml/modelFP8.mlmodel')\n",
    "coreml_orig = coremltools.models.MLModel('models/coreml/model.mlmodel')\n",
    "\n",
    "with open('models/coreml/labels.txt', 'r') as f:\n",
    "    labels = [l.strip() for l in f.readlines()]\n",
    "\n",
    "od_coreml_16 = CoreMLObjectDetection(coreml_16, labels)\n",
    "od_coreml_8 = CoreMLObjectDetection(coreml_8, labels)\n",
    "od_coreml_orig = CoreMLObjectDetection(coreml_orig, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tensorflow Quantization\n",
    "  \n",
    " ❗️ **Note:** Don't forget to copy ```models.tflite.python.predict_lite``` file while doing experiments on your own model. This file is not uploaded with the exported models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConverterError",
     "evalue": "TOCO failed. See console for info.\n/bin/sh: toco_from_protos: command not found\n\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-be71414d60c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFLiteConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_frozen_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/tflite/model.pb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Placeholder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'model_outputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_quantize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtflite_model_8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/tflite/modelFP8.tflite\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtflite_model_8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/lite/python/lite.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m           \u001b[0minput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m           \u001b[0moutput_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m           **converter_kwargs)\n\u001b[0m\u001b[1;32m    456\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m       result = _toco_convert_graph_def(\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_impl\u001b[0;34m(input_data, input_tensors, output_tensors, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m   data = toco_convert_protos(model_flags.SerializeToString(),\n\u001b[1;32m    441\u001b[0m                              \u001b[0mtoco_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                              input_data.SerializeToString())\n\u001b[0m\u001b[1;32m    443\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/lite/python/convert.py\u001b[0m in \u001b[0;36mtoco_convert_protos\u001b[0;34m(model_flags_str, toco_flags_str, input_data_str)\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_convert_to_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m       raise ConverterError(\n\u001b[0;32m--> 205\u001b[0;31m           \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\n\u001b[0m\u001b[1;32m    206\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;31m# Must manually cleanup files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConverterError\u001b[0m: TOCO failed. See console for info.\n/bin/sh: toco_from_protos: command not found\n\n\n"
     ]
    }
   ],
   "source": [
    "# Compress TensorFlow model\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph('models/tensorflow/model.pb', ['Placeholder'], ['model_outputs'])\n",
    "converter.post_training_quantize = True\n",
    "tflite_model_8 = converter.convert()\n",
    "open(\"models/tensorflow/modelFP8.tflite\", \"wb\").write(tflite_model_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-6c3302055d07>:7: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    }
   ],
   "source": [
    "# Setup TensorFlow Original Model\n",
    "\n",
    "from models.tensorflow.python.predict import TFObjectDetection as OrigTFObjectDetection\n",
    "from models.tensorflow.python.predict_lite import TFObjectDetection as LiteTFObjectDetection\n",
    "\n",
    "graph_orig = tf.GraphDef()\n",
    "with tf.gfile.FastGFile('models/tensorflow/model.pb', 'rb') as f:\n",
    "    graph_orig.ParseFromString(f.read())\n",
    "        \n",
    "# Load labels\n",
    "with open('models/tensorflow/labels.txt', 'r') as f:\n",
    "    labels = [l.strip() for l in f.readlines()]\n",
    "\n",
    "od_tflite_orig = OrigTFObjectDetection(graph_orig, labels)\n",
    "\n",
    "od_tflite_8 = LiteTFObjectDetection('models/tensorflow/modelFP8.tflite', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Models Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.customvision.prediction import CustomVisionPredictionClient\n",
    "\n",
    "prediction_key = ''\n",
    "predictor = CustomVisionPredictionClient(prediction_key, endpoint=endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipe import Pipe\n",
    "\n",
    "@Pipe\n",
    "def apply_quantized_model(stream, data_dir, model, dest_field):\n",
    "    return (\n",
    "        stream \n",
    "        | mp.apply('filename', dest_field + '_raw', lambda x: model.predict_image(Image.open(join(data_dir, x))))\n",
    "        | mp.apply([dest_field + '_raw', 'width', 'height'], dest_field, lambda x: x[0]\n",
    "            | mp.select(lambda p: format_dict(p, x[1], x[2]))\n",
    "            | mp.as_list\n",
    "        )\n",
    "        | mp.delfield([dest_field + '_raw'])\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "val2 = (\n",
    "    val\n",
    "    # Predict using online CustomVision\n",
    "    | mp.apply('filename', 'raw_cv', \n",
    "        lambda x: predictor.predict_image(project.id, open(join(data_dir, x), mode=\"rb\"), iteration.id).predictions)\n",
    "    | mp.apply(['raw_cv', 'width', 'height'], 'cv_predictions', lambda x: x[0]\n",
    "        | mp.select(lambda p: cv_prediction_as_dict(p, x[1], x[2]))\n",
    "        | mp.as_list\n",
    "      )    \n",
    "    # Predict using CoreML original\n",
    "    | apply_quantized_model(data_dir, od_coreml_orig, 'coreml_orig_predictions') \n",
    "    | mp.as_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(stream, open('results.pickle', 'wb'))\n",
    "# stream = pickle.load(open('results.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print reports\n",
    "\n",
    "\n",
    "for pred_field in [key for key in stream[0].keys() if 'predictions' in key]:\n",
    "    print(\"\\n===== %s =====\\n\" % pred_field)\n",
    "    print_report(\n",
    "        stream=val, \n",
    "        input_tags=input_tags, \n",
    "        prob_thresh=0.3, \n",
    "        overlap_thresh=0.3,\n",
    "        pred_field=pred_field, \n",
    "        gt_field='ground_truth'\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

